{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSCI 100 - Introduction to Data Science\n",
    "\n",
    "\n",
    "## Lecture 12 - Visualizing high dimensional data & Data Science wrap-up\n",
    "\n",
    "\n",
    "### 2019-04-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Output of K means multivariate clustering from tutorial\n",
    "\n",
    "```\n",
    "K-means clustering with 3 clusters of sizes 123, 389, 288\n",
    "\n",
    "Cluster means:\n",
    "     Total       HP    Attack   Defense   Sp. Atk   Sp. Def    Speed\n",
    "1 622.5691 88.91057 117.72358 100.65854 116.33333 101.86179 97.08130\n",
    "2 472.9666 77.19280  85.30077  80.95373  77.54499  79.02057 72.95373\n",
    "3 303.8958 50.14931  53.95486  52.78472  47.85417  49.49306 49.65972\n",
    "\n",
    "Clustering vector:\n",
    "  [1] 3 2 2 1 3 2 2 1 1 3 2 2 1 3 3 2 3 3 2 2 3 3 2 1 3 2 3 2 3 2 3 2 3 2 3 3 2\n",
    " [38] 3 3 2 3 2 3 2 3 2 3 2 3 2 2 3 2 3 2 3 2 3 2 3 2 3 2 3 1 3 3 2 3 2 2 1 3 2\n",
    " [75] 2 3 2 2 3 2 3 2 2 2 2 3 2 1 3 2 3 3 2 3 2 3 2 3 2 3 2 2 1 3 3 2 3 2 3 2 3\n",
    "[112] 2 3 2 2 2 3 3 2 3 2 2 2 2 1 3 2 3 2 3 2 2 2 2 2 2 2 1 2 3 2 1 2 3 3 2 2 2\n",
    "[149] 2 3 2 3 2 2 1 2 1 1 1 3 2 1 1 1 1 1 3 2 2 3 2 2 3 2 2 3 2 3 2 3 2 3 2 2 3\n",
    "[186] 2 3 3 3 3 2 3 2 3 3 2 1 2 3 2 2 2 3 3 2 3 3 2 2 3 2 2 2 2 2 2 3 2 2 3 2 2\n",
    "[223] 2 2 1 3 2 2 2 1 2 2 1 2 3 2 3 2 3 2 3 3 2 3 2 2 3 2 1 2 3 2 2 2 3 3 2 3 3\n",
    "[260] 3 2 2 1 1 1 3 2 1 1 1 1 1 3 2 2 1 3 2 2 1 3 2 2 1 3 2 3 2 3 3 2 3 3 3 3 2\n",
    "[297] 3 3 2 3 2 3 2 3 3 2 1 3 2 3 2 3 2 1 3 2 3 3 3 2 3 2 3 3 3 3 3 2 3 2 3 2 2\n",
    "[334] 1 3 2 2 3 2 1 2 2 2 2 2 3 2 3 2 1 2 2 3 2 1 2 3 2 3 3 3 2 3 2 3 2 1 2 2 2\n",
    "[371] 2 3 2 3 2 3 2 3 2 3 2 3 2 2 2 3 2 1 3 2 2 2 2 1 3 3 2 1 3 2 2 3 2 2 2 3 3\n",
    "[408] 2 1 1 3 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 2 2 3 2 2 3 2 2 3 3 2\n",
    "[445] 3 2 3 3 3 3 2 3 2 3 2 3 2 3 2 2 2 2 3 2 2 3 2 3 2 3 2 2 3 2 3 2 1 2 2 3 2\n",
    "[482] 3 3 2 3 2 3 3 3 2 2 3 2 1 1 2 3 2 1 3 2 3 2 3 2 2 3 2 3 3 2 1 2 2 2 2 2 2\n",
    "[519] 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 3\n",
    "[556] 2 2 3 2 2 3 2 2 3 2 3 3 2 3 2 3 2 3 2 3 2 3 2 3 3 2 3 2 3 2 2 3 2 3 2 2 2\n",
    "[593] 3 2 2 3 3 2 2 2 3 3 2 3 3 2 3 2 3 2 2 3 3 2 3 2 2 2 3 2 3 2 2 3 2 3 2 2 1\n",
    "[630] 3 2 3 2 3 2 3 2 2 3 3 2 3 2 3 2 2 3 2 2 3 2 3 2 3 2 2 3 2 3 2 3 2 2 3 2 2\n",
    "[667] 3 2 3 3 2 3 2 2 3 2 2 3 2 2 3 2 2 3 2 3 2 2 3 2 3 2 2 2 3 2 1 3 1 1 1 1 1\n",
    "[704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 2 2 3 2 2 3 2 2 3 2 3 3 2 3 3 2 3 2 3 3 1\n",
    "[741] 3 2 3 2 2 3 2 2 3 2 2 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 2 2 2 2 3 2 1\n",
    "[778] 2 3 2 3 3 3 3 2 2 2 2 3 2 3 2 1 1 1 1 1 1 1 1\n",
    "\n",
    "Within cluster sum of squares by cluster:\n",
    "[1]  908309.6 2188797.5 1152053.0\n",
    " (between_SS / total_SS =  73.1 %)\n",
    "\n",
    "Available components:\n",
    "\n",
    "[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n",
    "[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Output of K means multivariate clustering from tutorial\n",
    "\n",
    "- we can look at total within sum of squares (but really only useful for comparing models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- we can look at the ratio of between sum of squares / total sum of squares \n",
    "    - if very small, then there are no discernable clusters\n",
    "    - if 100, then each point is its own cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*neither of these are very intuitive (at least to me)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is intuitive?\n",
    "\n",
    "Visualization! A picture says 1000 words!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## t-sne\n",
    "\n",
    "- a popular dimensonality reduction algorithm useful for visualizing multi-dimensional data sets\n",
    "- no \"model\" given from t-sne (only works to visualize the data you currently have)\n",
    "- *see links in worksheet for more details about the specifics of the algorithm if you are interested*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### t-sne visualization of gene expression data from cells in a region of the brain\n",
    "\n",
    "- each data point in this picture corresponds to a single brain cell for which we have the expression level measurements for thousands of genes.\n",
    "\n",
    "<img align=\"left\" src=\"img/gene_expression_t-sne.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "source: Cembrowski, M.S., Wang, L., Lemire, A., DiLisio, S.F., Copeland, M., Clements, J., Spruston, N. The subiculum is a patchwork of discrete subregions. eLife 7, [doi:10.7554/eLife.37701, 2018](https://elifesciences.org/articles/37701)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### t-sne visualization of hand-written digits data set overlaid with class identification\n",
    "- each data point is an image of a handwritten digit for which we have 784 pixel values \n",
    "\n",
    "<img align=\"left\" src=\"https://d3ansictanv2wj.cloudfront.net/images/digits_tsne-5d3f7058.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "source: https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# COURSE EVALUATIONS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In January, we started with this Gif\n",
    "\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/up25s7QBalEmQ/giphy.gif\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And we laid out these goals and this path:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## High-level goals of this course:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Learn how to use reproducible tools (Jupyter + R) to do data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Learn how to solve 3 common problems in Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problems we will focus on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Predict a class/category for a new observation/measurement (*e.g.,* cancerous or benign tumour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Predict a value for a new observation/measurement (*e.g.,* 10 km race time for a 35 year old with a BMI of 25). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Find previously unknown/unlabelled subgroups in your data (*e.g.,* products commonly bought together on Amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another way to think of what we did in this course:\n",
    "\n",
    "![](https://d33wubrfki0l68.cloudfront.net/571b056757d68e6df81a3e3853f54d3c76ad6efc/32d37/diagrams/data-science.png)\n",
    "\n",
    "source: [R for Data Science](https://r4ds.had.co.nz/) by Grolemund & Wickham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where to from here\n",
    "\n",
    "- you learned a lot in this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- many of you are asking for more Data Science (yeah!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- so here's a list of some UBC courses of interest you might want to take:\n",
    "    - [STAT 306 - Finding Relationships in Data](https://harlanhappydog.github.io/STAT306/)\n",
    "    - [STAT 406 - Methods for Statistical Learning](https://github.com/msalibian/STAT406)\n",
    "    - CPSC 330 - Applied Machine Learning (Instructor coming to give a sneak peak today)\n",
    "    - [CPSC 340 - Machine Learning](https://www.cs.ubc.ca/~fwood/CS340/)\n",
    "    - [MATH 210 - Introduction to Mathematical Computing](https://github.com/ubc-math210/2018)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- outside of classes, I can recommend reading [An Introduction to Statistical Learning](https://www-bcf.usc.edu/~gareth/ISL/) and the [John Hopkins Coursera Data Science courses](https://www.coursera.org/specializations/jhu-data-science)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank-you and it's been a blast!\n",
    "\n",
    "<img align=\"left\" src=\"https://media.giphy.com/media/12xvz9NssSkaS4/giphy.gif\" width=\"500\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
